{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron\n",
    "\n",
    "퍼셉트론은 가장 단순한 판별 함수 기반 예층 모형이다 (discrimiant function)\n",
    "\n",
    "Input 백터 $x = \\begin{bmatrix}x_1\\\\ \\vdots\\\\ x_d \\end{bmatrix}\\;$ 와 그의 가중치 백터가 있다고 할 때 $\\omega = \\begin{bmatrix}\\omega_1\\\\ \\vdots\\\\ \\omega_d \\end{bmatrix}$\n",
    "\n",
    "그 둘을 곱한 것이 판별함수가 된다.\n",
    "$f(x) = \\omega^Tx$\n",
    "\n",
    "<br>\n",
    "$$\n",
    "\\begin{align*} \\text{Approve credit if} \\;\n",
    "& \\sum\\limits_{i=1}^{d}\\omega_ix_i > \\text{threshold}, \\\\\n",
    "\\text{Deny credit if} \\;\n",
    "& \\sum\\limits_{i=1}^{d}\\omega_ix_i < \\text{threshold}.\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "$$\n",
    "h(x) = \\text{sign} \\left(\\left( \\sum\\limits_{i=1}^{d}\\omega_ix_i \\right)- \\text{threshold} \\right) = \\text{sign}\\left(\\left( \\sum\\limits_{i=1}^{d}\\omega_ix_i \\right)+ \\omega_0\\right)\n",
    "$$\n",
    "\n",
    "이떄의 sign 함수를 활성화 함수라고 하며, 일반적으로는 Heaviside step function으로 표기한다.\n",
    "\n",
    "를 퍼셉트론 이라고 한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron과 logical Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron에 논리적인 operation을 적용해 볼 수 있다. And, Or, Not 과 같은 operation은 사용이 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice!  You got it all correct.\n",
      "\n",
      "Input 1    Input 2    Linear Combination    Activation Output   Is Correct\n",
      "      0          0                    -4                    0          Yes\n",
      "      0          1                    -2                    0          Yes\n",
      "      1          0                    -1                    0          Yes\n",
      "      1          1                     1                    1          Yes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TODO: Set weight1, weight2, and bias\n",
    "weight1 = 3\n",
    "weight2 = 2\n",
    "bias = -4\n",
    "\n",
    "\n",
    "# DON'T CHANGE ANYTHING BELOW\n",
    "# Inputs and outputs\n",
    "test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "correct_outputs = [False, False, False, True]\n",
    "outputs = []\n",
    "\n",
    "# Generate and check output\n",
    "for test_input, correct_output in zip(test_inputs, correct_outputs):\n",
    "    linear_combination = weight1 * test_input[0] + weight2 * test_input[1] + bias\n",
    "    output = int(linear_combination >= 0)\n",
    "    is_correct_string = 'Yes' if output == correct_output else 'No'\n",
    "    outputs.append([test_input[0], test_input[1], linear_combination, output, is_correct_string])\n",
    "\n",
    "# Print output\n",
    "num_wrong = len([output[4] for output in outputs if output[4] == 'No'])\n",
    "output_frame = pd.DataFrame(outputs, columns=['Input 1', '  Input 2', '  Linear Combination', '  Activation Output', '  Is Correct'])\n",
    "if not num_wrong:\n",
    "    print('Nice!  You got it all correct.\\n')\n",
    "else:\n",
    "    print('You got {} wrong.  Keep trying!\\n'.format(num_wrong))\n",
    "print(output_frame.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q. The way to go from an __AND__ perceptron to an __OR__ perceptron\n",
    "\n",
    "- Decrease the magnitude of the bias\n",
    "- Increase the weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 퍼셉트론의 손실함수\n",
    "\n",
    "퍼셉트론의 예측 오차를 최소화 해야하는데, 그걸 가중치 $\\omega$를 최소화 하면서 찾게 된다. 가중치에 따라 실제값과 예측값이 달라지게 되는데, 전체 예측오차는 i 번째 개별 데이터의 손실함수로 정의할수 있다.\n",
    "$$\n",
    "E = \\sum_{i=1}^N L(\\hat{y}_i, y_i)\n",
    "$$\n",
    "\n",
    "$$\n",
    "L(\\hat{y}_i, y_i) = \\max(0, -\\hat{y}_iy_i)\n",
    "$$\n",
    "\n",
    "$$\n",
    "E = \\sum_{i=1}^N \\max(0, -\\hat{y}_iy_i) = - \\sum_{i \\in M} \\hat{y}_i y_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가중치 계산\n",
    "$E(\\omega)$를 최소화 시키는 가중치는, $\\omega$로 미분하여 gradient를 구한다.\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "w_{k+1} \n",
    "&=& w_{k} + \\eta_k \\sum_{i \\in M} x_i y_i \\\\\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "여기서 여기에서  η 는 step size 또는 learning rate 이라고 부른다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
