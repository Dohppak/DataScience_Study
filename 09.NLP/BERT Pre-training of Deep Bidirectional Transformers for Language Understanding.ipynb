{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract\n",
    "\n",
    "둘다 Transformer 로 부터 나오게 됩니다. \n",
    "GPT는 Decoder를 쓰면서 언어모델을 사용하게 되고, Encoder로 언어모델을 학습해보면 어떨까?\n",
    "- Masked Language Model : 빈칸채우기 맞추기\n",
    "\n",
    "- Transformer structure :\n",
    "- WordPiece embedding : GNMT \n",
    "    - BPE 와 유사하다\n",
    "    - SentnecePiece 가 있다.\n",
    "- Positional embedding\n",
    "\n",
    "#### Input\n",
    "\n",
    "- Position Embedding\n",
    "- Segment Embedding\n",
    "    - 문장을 나누게 됩니다.\n",
    "    - 길이는 무조건 512가 됩니다.\n",
    "- Token Embedding\n",
    "    - Feature embedding, ELMo\n",
    "\n",
    "\n",
    "512가 넘어가면, 뺴게 됩니다. 그리고 \n",
    "\n",
    "총 3개의 메트릭스를 학습하게 됩니다.\n",
    "\n",
    "- BERT\n",
    "- OpenAI GPT :\n",
    "- ELMo : Bi-directional LSTM\n",
    "\n",
    "### Model\n",
    "\n",
    "- 80% 는 Masking\n",
    "- 10% 는 Negative\n",
    "- 10% 는 Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
