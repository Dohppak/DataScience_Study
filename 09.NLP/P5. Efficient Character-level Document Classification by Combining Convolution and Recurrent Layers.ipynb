{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficient Character-level Document Classification by Combining Convolution and Recurrent Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstact\n",
    "__연구의의__\n",
    "<br>\n",
    "기존 문서분류는 Word-level에서 이루어졌습니다. 이 연구는 Character-level input 에 대하여, encoding 과정에서 CNN과 RNN을 이용한 NN 아키텍쳐를 구성했습니다.\n",
    "<br>\n",
    "\n",
    "__기존 Character level 연구와의 차이점__\n",
    "<br>\n",
    "Character-level Convolutional Networks for Text Classification에 RNN을 더해서 훨씬 적은 파라미터를 활용하여 성능을 만들어 냈습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "\n",
    "#### Word level의 한계점\n",
    "- Statistically inefficient\n",
    "    - 각각의 토큰들은 분리되고 동일한 수의 파라미터를 가지게 됩니다. 하지만 많은 단어들은 같은 root, prefix, suffix를 공유합니다.\n",
    "\n",
    "- out-of-vocabulary word\n",
    "    - 단어장 외에 있는 단어들은 token으로 인식이 안됩니다. Word-level에서는 unknown token으로 분류하게 됩니다. 하지만 이러한 문제는 훈련된 모델을 다른 도메인에서 사용할 시에, 문제가 됩니다.\n",
    "\n",
    "- Missing spell\n",
    "    - social network 같은곳에 있는 축약어나, 오타등을 잘 못잡게 됩니다.\n",
    "    \n",
    "- reference\n",
    "    - https://www.edwith.org/deepnlp/lecture/29225/\n",
    "    \n",
    "#### 기존의 Character level 방법론\n",
    "\n",
    "-  Character-level Convolutional Networks for Text Classification (Zhang et al., 2015) \n",
    "    - 다중 convolution layer를 구성하고, max-pooling을 하였다. 각 layer는 우선적으로 feature를 small 부터 뽑아낸다. 마지막 컨볼류선 레이어는 백터의 모양을 flatten하게 activation 시킨다. 그 다음에 fully connected layer로 연결한다.\n",
    "    - 한계점 : 각 convolution layer의 Receptive field가 작아서(3,7), 네트워크의 layer가 input sequecne의 long-term dependency를 고려하여 커져야합니다.\n",
    "    \n",
    "<img src='./img/charlevel.png' width=100%>\n",
    "\n",
    "\n",
    "- Very deep convolutional network\n",
    "    - 6개의 convolution layer 와 2개의 fully-connected layer의 연결로 구성하였다.\n",
    "    - 한계점 : 파라미터 수의 급격한 증가가 있다.\n",
    "    \n",
    "<img src='./img/VDDN.png' width=80%>\n",
    "\n",
    "\n",
    "#### 이 논문의 포인트\n",
    "\n",
    "위에서 언급한 Character-level sequence의 비효율을 해결하기위해서 이 논문에서는 CNN과 RNN의 결합을 소개한다.이 결합 모델은 single recurrent layer 와 CNN 으로 구성되어 있다. RNN의 경우 GRU또는 LSTM의 사용을 통해 long-term dependency를 해결한다. 또한 CNN이 더 적은 컨볼루션 레이어를 사용하게 한다.\n",
    "\n",
    "#### Evaluation\n",
    "\n",
    "Character-level Convolutional Networks for Text Classification 에서 제시한 8개의 large-scale document classification task를 해보고자한다. 8개의 문서분류 문제를 풀어보고, Character-level convolutional networks for text classification와 성능 비교해보자고 한다. 더 적은 모델을 통해서, 비슷한 성능을 내는것을 목표로 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Building Blocks: Neural Network Layers\n",
    "\n",
    "<img src='./img/convrnn.png' width=50%>\n",
    "\n",
    "#### Embedding Layer\n",
    "- $e_{t}=Wx_{t}$\n",
    "- 각 문서들은 one-hot vector의 sequence로 나타냅니다. \n",
    "- 학습된 weight matrix가 W입니다.\n",
    "\n",
    "#### Convolution Layer\n",
    "\n",
    "#### Recurrent Layer\n",
    "- 이전 hidden step의 input을 받아서 다음번 step의 output으로 내보냅니다. \n",
    "- Recursive function\n",
    "- $h_{t} = f(x_{t}, h_{t−1})$\n",
    "- $h_{t} = tanh (W_{x}x_{t} +U_{h}h_{t−1})$ ,\n",
    "- NLP 에서 RNN은 문장의 정보를 시간의 순서에 따라 압축 할 수 있습니다.\n",
    "<img src='./img/rnn.png' width=70%>\n",
    "\n",
    "\n",
    "\n",
    "#### LSTM & GRU\n",
    "- RNN은 문장이 많이 길어질 수록 고정된 메모리에 압축된 정보를 담아야 하기 때문에, 앞에서 학습한 정보를 잊습니다. 이는 곧 정보의 손실을 뜻합니다. \n",
    "- LSTM 은 이를 해결하기 위해 cell state를 RNN에 추가합니다\n",
    "- input,output, forget gates and candidate memory cell 됩니다.\n",
    "\n",
    "- $f_{t} = \\sigma(W_{f}x_{t} +U_{f}h_{t−1})$\n",
    "    - ‘과거 정보를 잊기’를 위한 게이트입니다. $h_{t−1}$과 $x_{t}$를 받아 시그모이드를 취해준 값\n",
    "- $c˜_{t} = tanh (W_{c}x_{t} +U_{c}h_{t−1})$\n",
    "- $i_{t} = \\sigma(W_{i}x_{t} +U_{i}h_{t−1})$ \n",
    "    - ‘현재 정보를 기억하기’ 위한 게이트입니다.\n",
    "- $o_{t} = \\sigma(W_{o}x_{t} +U_{o}h_{t−1})$ \n",
    "\n",
    "<img src='./img/LSTM1.png' width=70%>\n",
    "<img src='./img/LSTM.png' width=70%>\n",
    "\n",
    "#### Bidirectional Recurrent Layer\n",
    "- 또한 토큰을 순차적으로 하나씩 읽어야 하기 때문에, 훈련 할때 속도가 기타 네트워크 보다 느립니다.\n",
    "- Bidirection RNN 은 양쪽 방향으로 전파시킨다음에 concat 합니다.\n",
    "<img src='./img/birnn.png' width=100%>\n",
    "\n",
    "#### Classification Layer \n",
    "- Classification 을 위해 logistic regression 을 사용하였습니다.\n",
    "- 위 Convolution layer 와 Recuurent layer 의 결과가 문장의 길이 $D$ 에 따른 다양한 길이를 가진 sequence를 반환해도 fixed-dimension의 vector를 얻을수 있습니다.\n",
    "\n",
    "<br>\n",
    "\n",
    "- reference \n",
    "    - https://nlpoverview.com/#4\n",
    "    - https://ratsgo.github.io/natural%20language%20processing/2017/03/09/rnnlstm/\n",
    "    - https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setting\n",
    "\n",
    "<img src='./img/efficonvrnn.png' width=100%>\n",
    "\n",
    "#### Model Describtion\n",
    "- Vocabulary 은 96개의 단어로, 대소문자, 숫자, ?!, 공백까지 포함합니다. \n",
    "- 단어 embedding size는 8 입니다.\n",
    "- Convolution layer의 경우 2~5개를 배치합니다. \n",
    "- d' = 128 짜리 filter를 적용합니다. AG, Yahoo의 경우 1024 filter로 실험을 추가해봅니다.\n",
    "    - Filter를 128개 사용한다고 합니다.\n",
    "    - Filter 는 detect하고자 하는 feature에 대한 내용\n",
    "- Receptie field size는 r로 설정하며, depth에 따라 5,3이 됩니다. \n",
    "    - Receptive Field는 Filter size로 진행하면서 detect되는 실제 값\n",
    "- Max pooling size r'은 2로 합니다. \n",
    "- ReLU 씁니다. \n",
    "- Recurrent layer의 경우, single layer에 birectional LSTM을 모든 모델에 적용합니다. Hidden state는 128의 차원을 가집니다.\n",
    "- Dropout 을 사용합니다. \n",
    "    - Convolution layer 와 Recurrent Layer 모두 사용합니다.\n",
    "- AdaDelta with $ρ$ = 0.95, $\\epsilon$ = 10−5 \n",
    "- batch size of 128.\n",
    "- Gradient 가 L2 norm에서 5보다 커질때, rescale 합니다.\n",
    "- Early stopping 합니다.\n",
    "    - patience value를 도입합니다.\n",
    "    - 현재 상태에서 가장낮은 validation loss가 0.5보다 낮을시, patience 를 2배로 확장합니다.\n",
    "    - epoch가 patience value 보다 커지면 학습을 멈춥니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Setting\n",
    "\n",
    "<img src='./img/8dataset.png' width=100%>\n",
    "\n",
    "- Task\n",
    "200,000 ~ 4,000,000개의 문서를 sentiment analysis, ontology classification, Question type classification, news categorizeation 등을 준비했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "\n",
    "<img src='./img/p5result.png' width=100%>\n",
    "\n",
    "- C$C$R$R$F$F$D$D$ refers to a network with $C$ convolutional layers, $R$ recurrent layers, $F$ fully-connected layers and $D$ dimensional feature vectors\n",
    "- Classes 의 수가 증가할수록, 우리의 모델은 더 좋은 퍼포먼스를 낼 수 있습니다. \n",
    "- 더 적은 pooling layer를 사용하면서 구체적인 정보를 더 보존합니다.\n",
    "- 적은 데이터 사이즈에서 더 잘 작동합니다.\n",
    "- 컨볼루션 레이어는 2~3개일때 가장 잘 작동합니다\n",
    "- 필터갯수의 증가는 파라미터 갯수 증가에 비해 성능개선이 약합니다\n",
    "\n",
    "## Conclusion\n",
    "제안한 모형은 class 숫자 증가에 따라, 데이터셋이 적을수록, 그리고 컨볼루션 레이어가 2~3개일때 가장 잘 작동했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A\n",
    "\n",
    "Q. NLP에서 RNN레이어의 Dropout 방법론?\n",
    "- layer norm\n",
    "- recurrent dropout\n",
    "- variational dropout\n",
    "    - 타임스탭별로 얻어가야한다.\n",
    "    - 배치안에서 계산해야한다.\n",
    "\n",
    "Q. 자연어 처리에서의 Data Argmentation을 어떻게 하나요?\n",
    "- argmentation이 잘못되면 문장의미가 꺠진다.\n",
    "- 유의어 기반으로 교체한다.\n",
    "- 번역모델로 argmentation 하는게 좋을 것이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://arxiv.org/abs/1602.00367"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
