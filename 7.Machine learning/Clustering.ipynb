{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "- unsupervised learning\n",
    "- Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why clustering?\n",
    "\n",
    "- Let's look at the problem in a different angle\n",
    "    - The issue here is dealing with high-dimensional data\n",
    "\n",
    "- How do people deal with high-dimensional data?\n",
    "    - Start by finding interesting patterns associated with the data\n",
    "    - Clustering is one of the well0known techniques with successful applications on large domain for finding patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "- Group data points that are close to each others\n",
    "- identify such groupings in an unsupervised manner\n",
    "    - Unsupervised : no information is provided to the alogorithm on which data points belong to wich clusters\n",
    "- PCA , not LDA (no label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose of Clustering on Microarray\n",
    "\n",
    "- Visualization of data\n",
    "- hypothesis generation\n",
    "- tool for feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### overview\n",
    "\n",
    "- Patterns : Feature selection / Extraction\n",
    "- Representation : Interpattern similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feature selection\n",
    "    - Do not change data : Identifying the most effective subset of the original features to use.\n",
    "    - Good for Interpretation.\n",
    "- Feature Extraction\n",
    "    - Transformations of the input features to produce new salient features.\n",
    "- Interpattern Similarity\n",
    "    - measured by a distance function defined on pairs of patterns\n",
    "- Grouping\n",
    "    - Mehtods to group similar patterns in the same cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity measure\n",
    "\n",
    "- Input data to algorithm is usually a vector (Tuple, reocrd, instance)\n",
    "- Types of Data : Numberical, Categorical, Boolean, Ordinal\n",
    "- Must also inculde a method for __computing similarity of or distance__ between vectors\n",
    "\n",
    "#### Similarity (No single answer)\n",
    "- Data structures\n",
    "    - Data matrix \n",
    "- Dissimilarity matrix\n",
    "    - one mode : upper or lower\n",
    "    \n",
    "#### Similarity measure\n",
    "- Jagota defines dissimilarity, \n",
    "<br/>$f(x,y)$>$f(w,z)$\n",
    "- if and noly if x is less silmilar to y than w is to z\n",
    "- This is always a pair-wise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continuous Various\n",
    "\n",
    "__Scaling__\n",
    "- Standardize data : Scale issue\n",
    "- Using mean absolute deviation is more __robust__ than using standard deviation\n",
    "<br/>\n",
    "\n",
    "__Distance__\n",
    "- Euclidean distance : 2 norm\n",
    "- Manhattan distance\n",
    "- Minkowski distance : m norm\n",
    "<br/>\n",
    "\n",
    "__Correlation__\n",
    "- They only capture trends\n",
    "- Pearson Linear Correlations.\n",
    "\n",
    "$Similarity = (1-Correaltion) / 2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary Various\n",
    "\n",
    "__Coefficient__\n",
    "- Simple matching coefficient (Symmetric)\n",
    "- Jaccard coefficient (Assymmetric) : Textmining\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nominal Various\n",
    "\n",
    "- A generalization of the binary variable in that it can take more than 2 states\n",
    "    - Method 1 : Simple matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordinal Various"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Clusering\n",
    "\n",
    "- There are two style\n",
    "    - Agglomerative (bottom-up)\n",
    "        - Beginning with singletons (sets with 1 element)\n",
    "        - Merging them until S is achieve \n",
    "        - Depending on Threshold\n",
    "        - dendrogram\n",
    "<br/>\n",
    "    - Divisive (Top-down)\n",
    "        - Recursively partitioning S until singleton sets are reached.\n",
    "        \n",
    "<br/>\n",
    "- Linkage in Hierarchical clustering\n",
    "    - Depending on distance\n",
    "        - Average Linkage : K-means\n",
    "        - Single Linkage : The minimum of all pairwise distances between points in the two clusters (Loose)\n",
    "        - Complete Linkage: The maximum of all pairwise distances between points in the two clusters (Tight)\n",
    "<br/>\n",
    "#### Problem\n",
    "- Distinct clusters are not produced - Somethimes this can be good, if the data has a hierarchical structure\n",
    "- There are methods for producting distinct clusters\n",
    "\n",
    "\n",
    "#### Advantage\n",
    "- Visualization\n",
    "- Provides hierarchical relation \n",
    "- Shown to be able to capture concentric clusters\n",
    "- Provide hierarchical distance\n",
    "\n",
    "#### Disadvantage\n",
    "- Not easy and not using\n",
    "\n",
    "#### Example\n",
    "- AGNES (Agglomerative Nesting)\n",
    "- DIANA (Divisive Analtsis : Top down)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means Clustering (Hard Clustering) \n",
    "\n",
    "1. Choose a number of clusters K (But How we know K?)\n",
    "2. Initalize cluster centers $u_1,u_2.....,u_k$\n",
    "    - Could pick K data points(sample) and set cluster centers to these points\n",
    "    - Or could randomly assign points(sample) to clusters and take means of clusters\n",
    "3. For each data point, compute the cluster center it is closet to and assign the data point to this cluster\n",
    "4. Re-Compute cluster centers\n",
    "5. Stop when there are no new re-assignments\n",
    "\n",
    "iteration 20~30\n",
    "\n",
    "#### Stopping criteria\n",
    "- No change in the members of all clusters\n",
    "- When the squared error is less than some small threshold value $\\alpha$ = $10^{-3}$\n",
    "    - Squared error se\n",
    "    - sequare error's difference < $a$ after jth iteration\n",
    "    - initialization : 10 times\n",
    "- Properties of K-means\n",
    "    - Guaranteed to converge\n",
    "    - Guaranteed to achieve local optimal, not necessarily global optimal.\n",
    "    \n",
    "\n",
    "#### Determining # of Clusters\n",
    "\n",
    "- We'd like to have a measure of cluster quality Q and then try different values of k until we get an optimal value for Q\n",
    "- But, since clustering is an unsupervised learning method, \n",
    "- Cluser Quality Measures\n",
    "    - Jagota : suggests a measure that emphasizes cluster tightness or homogeneity\n",
    "    - This is a plot of the Q measure for k-means clustering on the data shown earlier\n",
    "    - How many clusters do you think there actually are? \n",
    "- The Q measure takes into account homogeneity within clusters, but not separation between clusters\n",
    "- Other measures try to bomine these two characteristics. (Davies-Bouldin measure, Silhouette)\n",
    "- Alternate approach is to look at cluster stability:\n",
    "    - Add random noise to the data many times and count how many pairs of data points no longer clusters\n",
    "- Silhouette measure : threshold = mean vaule\n",
    "- interprtability : 중요하다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Fuzzy C-Clustering (Soft - Have probability)\n",
    "\n",
    "- Not partfitions\n",
    "- Let $X_i$ be a vecto of value for data point $G_i$.\n",
    "    - 1. Initialize membership U for data point g of cluster c by random\n",
    "    - 2. At the k-th step, compute the fuzzy centroid C for, where nc is the number of clusters\n",
    "        - $C_j$ is mean.\n",
    "        - m is fuzzy parameter.\n",
    "        - n is number of data points.\n",
    "    - 3. Update the fuzzy membership (categorize data)\n",
    "    - 4. If $U_k$ - $U_{k-s}$ < threshold, then stop, else return to step2\n",
    "- Allows a datapoint to be in multiple clusters\n",
    "- A more natural representation of the behavior of genes\n",
    "    - genes usally are invlved in multiple functions.\n",
    "- Need to define c, the number of clusters.\n",
    "- Need to determin membership cutoff value.\n",
    "- Clusters are sensitive to inital assignment of centroids\n",
    "    - Fuzzy c-means is not a deterministic algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Nonlinear => Not good K-means\n",
    "- Artifical data => with algoritm is very well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
