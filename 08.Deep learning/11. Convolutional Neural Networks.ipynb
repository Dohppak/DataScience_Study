{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- http://taewan.kim/post/cnn/\n",
    "- http://bcho.tistory.com/1149"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network\n",
    "\n",
    "이미지 분류를 위한 신경망 구조, 세상의 실제 이미지들은 생각보다 정형화 되어있지 않습니다. 따라서 컴퓨터가 다른 구도의 같은 이미지를 이해하려면 많은 학습량이 필요하게 됩니다. 이 뜻은 파라미터의 크기가 엄청나게 커진다는 것입니다.\n",
    "\n",
    "이러한 문제를 해결하기 위해서, 처음에는 가장 기초가 되는 특징을 확인하고, 그 특징들을 조합하여, 복잡한 특징이 존재하는지를 살펴본 뒤, 마지막으로 물체를 분류하고자 했습니다.\n",
    "\n",
    "CNN은 기존의 Fully Connected NerualNetwork와 비교하여 다음과 같은 차별성을 갖습니다.\n",
    "- 각 레이어의 입출력 데이터의 형상 유지\n",
    "- 이미지의 공간 정보를 유지하면서 인접 이미지와의 특징을 효과적으로 인식\n",
    "- 복수의 필터로 이미지의 특징 추출 및 학습\n",
    "- 추출한 이미지의 특징을 모으고 강화하는 Pooling 레이어\n",
    "- 필터를 공유 파라미터로 사용하기 때문에, 일반 신공망에 비해 학습 파라미터가 매우 적음\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](img/10.CNN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN 역사\n",
    "\n",
    "CNN은 인간의 visual recognition과 높은 연관을 같습니다.\n",
    "\n",
    "인간의 시신경으로 부터 시작되는 시각인지의 영역과 매우 동일한 효과를 가지게 됩니다. edges and lines 로 부터 shapes, 그리고 objects 마지막으로 face까지 이어지는 구조를 가지게 됩니다. 아래 영역은 인간의 뇌로부터 Receptive fields size와 feature의 차이를 보이는 것을 보여줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN 구조\n",
    "\n",
    "CNN 은 이미지의 __특징을 추출__ 하는 부분과 __클래스를 분류__ 하는 부분으로 나눌 수 있습니다. \n",
    "<br>\n",
    "\n",
    "__특징 추출__ : Convolution Layer,Pooling Layer\n",
    "\n",
    "입력 데이터를 필터가 순회하며 합성곱을 계산하고, 그 계산 결과를 이용하여 Feature map을 만듭니다. Feature map는 sub-sampled 를 통해서 차원을 줄여주는 효과를 가지게 됩니다. Convolution Layer는 Filter 크기, Stride, Padding 적용여부, Max Pooling의 크기에 따라서 출력 데이터의 Shape이 결정됩니다. \n",
    "\n",
    "- Convolution Layer : 입력데이터에 필터(Filter or Weight)를 적용 후 활성함수를 반영하는 요소입니다.\n",
    "- Pooling Layer(Subsampling) : spatial 차원의 다운샘플링을 책임집니다.\n",
    "\n",
    "__클래스 분류__ : Fully Connected Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN 특징\n",
    "\n",
    "__Locality__<br>\n",
    "CNN에서 우리가 집중하는 부분은 object의 local structure 입니다. Filter는 전체를 다 보는게 아니라 일부분에 집중해서 보게됩니다. \n",
    "\n",
    "__Translation Invariance__<br>\n",
    "Object에 대한 인식은 location과 independent합니다. 부분적인 패턴은 location에 독립적입니다. 오디오의 경우에는 time에 대해서 독립적인 성격을 가질 수 있습니다. 이는 고양이가 몇 픽셀 이동해도 고양이임을 알아낼 수 있다는 것입니다. 텍스트라면 문장에서 도치법이 일어나도 문장의 의미를 잘 파악하는 것이 되겠군요. 그렇다면 오디오라면, 음악에서 악기를 도입부에 쓰거나, 후반부에 쓰더라도 사용된 악기의 특징을 찾을 수 있을 것입니다.\n",
    "\n",
    "__Weight sharing__<br>\n",
    "하나의 feature map을 만드는데는 동일한 filter를 사용하기 때문에, weight를 학습하는 filter의 경우 다들 이 weight를 공유하게 됩니다. 학습된 weight를 동일하게 spatial space에 적용되게 됩니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Convolution\n",
    "\n",
    "> 합성곱은 두 함수 f,g가운데 하나의 함수를 reverse, shift 시킨 다음에 다른 하나의 함수와 곱한 결과를 적분하는 것을 의미한다.\n",
    "\n",
    "컨볼루션 레이어는 입력데이터로부터 특징을 추출하는 역할을 합니다. 컨볼루션 레이어는 특징을 추출하는 필터(Fliter)와, 값을 비선형 값으로 바꾸어주는 확성함수로 이루어져 있습니다. 또한 입력 데이터는 일반적으러 3차원 tensor입니다. width, height 그리고 depth(channel)로 구성되어 있습니다. 하지만 batch 나 mini-batch를 활용할 경우에는 4D tensor를 사용하게 됩니다.\n",
    "\n",
    "Signal Processing 의 convolution과의 차이점은, Input과 convolution을 변형시키지 않다는 점입니다. Input과 Filter의 depth가 같다면, 바로 곱이 들어가게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/10.CNN3.jpg\" width = 50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Filter\n",
    "\n",
    "필터는 그 특징이 데이터에 있는지 없는지를 검출해주는 함수입니다. 필터는 행렬로서 정의가 뇝니다. 필터는 입력받은 데이터에서 그 특성을 가지고 있으면 큰값이 나오고, 특성이 없다면 결과값이 0에 가까운 값이 나오게 되서, 해당 특성이 있는지를 파악하게 해주게 됩니다.\n",
    "<br>\n",
    "\n",
    "__Filter & Kernel?__\n",
    "\n",
    "또한 필터는 이미지의 특징을 찾아내기 위한 공용 파라미터이기도 합니다. CNN에서 Filter와 Kernel 은 비슷한 의미로 사용됩니다. 필터는 지정된 간격으로 이동하면서, 전체 입력데이터와의 합성곱으로 하여 Feature Map을 만듭니다. Filter는 input을 돌면서 element wise product를 진행하고 결과를 계산해서 하나의 scalar값을 반환합니다. \n",
    "\n",
    "__Filter number__\n",
    "\n",
    "Filter에 들어갈 값들은 어떻게 결정되는 것일까요? DeepLearning은 파라미터를 학습하게 됩니다. 그렇기 때문에 Backpropagtion을 통해서 filter의 weight를 학습하는 것이 되는 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/Convolution_schematic.gif\" width = 50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Stride__\n",
    "\n",
    "필터는 입력데이터를 지정한 간격으로 순회하면서 합성곱을 계산합니다. 이때 필터를 순회하는 간격을 Stride라고 합니다. Stride 1로 둔다면 어떤 기능을 하게 될까요? 좀더 자세하게 input을 분석한다는 의미가 됩니다. 모든 spatial의 다운 샘플링은 pool 레이어에게 맡기게 됩니다. conv layer는 입력 볼륨의 깊이만을 변화시키게 됩니다.\n",
    "\n",
    "__Padding__\n",
    "\n",
    "일반적으로 우리가 $n$ input을 $f$사이즈의 filter를 이용해서 ouput을 산출한다면 $n-f+1$의 정방혈 행렬이 나오게 될것입니다. 이말은 처음의 input이미지로 부터 크기가 작아지는 현상이 발생하게 됩니다. 또한 filter의 진행방향에 따라서 가운데에 있는 픽셀들은 모서리나 가에 있는 픽셀들 보다 더 큰 영향력을 가지게 될 것입니다. 일반적으로 $f$, 필터는 홀수차원입니다. 필터가 짝수이면, 비대칭적인 padding이 필요합니다. 그리고 홀수 필터는 center지점을 가질수 있게됩니다.\n",
    "\n",
    "- Shrinking output\n",
    "- Through away into from edge\n",
    "\n",
    "패딩은 Feature Map의 크기가 입력데이터보다 작아지는 현상을 방지하는 방법입니다. 출력데이터와 입력데이터의 크기를 갖게 만들기 위해, 입력 데이터의 외각에 지정된 픽셀만큼 특정 값으로 채워 넣는 것을 의미합니다. \n",
    "\n",
    "만약 입력 데이터가 여러 채널을 갖을 경우, 필터는 각 채널을 순회하며, 합성곱을 계산한 후, 채널별 피처 맵을 만듭니다. 각 채널별 피처 맵을 합산하여, 최종 피처 맵을 반환합니다. 따라서 입력 데이터는 채널 수와 상관없이 필터 별로 하나의 피처맵을 구성합니다.\n",
    "\n",
    "- Valid Convolution : Padding을 붙이지 않는 것\n",
    "- Same Convolution : input과 output의 사이즈를 동일하게 하는 Padding 입니다.\n",
    "\n",
    "__Volume__\n",
    "\n",
    "Filter의 width를 input의 Channel과 동일하게 구성하는 것입니다. 그 결과 Feature Map은 3가지 Channel에서 계산된 결과값들의 합으로 구성될 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/PAD.png\" width = 70%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Activation Function__\n",
    "<br>\n",
    "Feature Map이 추출된 이후에는, Activation function 이 적용하게 된다. 정량적으로 나와있는 Feautre Map을 \"있다, 없다\"와 같은 비선형 값으로 바꿔주는 과정이 들어간다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 Convolution Layer 의 입력 데이터를 필터가 순회하며 합성곱을 통해서 만든 출력을 Feature Map 또는 Activation Map 이라고 합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Multiple filters__\n",
    "\n",
    "Channel이 동일한 여러개의 Filter들을 사용해서 두개의 output 형태를 일치시키면 그것을 width 축에 대해서 concat 시킵니다. 그러면 Volume 을 가지는 Feature Map을 형성할 수 있을 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Pooling Layer\n",
    "\n",
    "풀링레이어는 컨폴루션 레이어의 출력데이터를 입력으로 받아서 출력 데이터(Feature Map)의 크기를 줄이거나 특정 데이터를 강조하는 용도로 사용합니다. 일반적으로 더 적은 차원의 매트릭스가 구성됩니다. 이것은 Gradient Descent가 관여하는 learning에 관여하지 않습니다. 그저 feature map을 조절하는 용도로 사용되기 때문입니다. 일반적으로 pooling 시에는 padding을 잘 사용하진 않습니다. \n",
    "\n",
    "- Max Pooling\n",
    "- Average Pooling\n",
    "- Min Pooling\n",
    "\n",
    "위 풀링 레이어들은 Convolution layer 와 비교하여 다음과 같은 특징이 있습니다.\n",
    "- 학습대상 파라미터가 없음\n",
    "- 풀링 레이어를 통과하면 행렬의 크기가 감소\n",
    "- Pooling 레이어를 통해서 채널의 수 변경이 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/maxpool.png\" width = 100%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 레이어별 출력 데이터의 크기를 계산해보자.\n",
    "\n",
    "__Convolution layer 의 크기에 따른 Feature Map__\n",
    "<br>\n",
    "주요용어\n",
    "\n",
    "- 입력 데이터 높이: H\n",
    "- 입력 데이터 폭: W\n",
    "- 필터 높이: FH\n",
    "- 필터 폭: FW\n",
    "- Strid 크기: S\n",
    "- 패딩 사이즈: P\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{OutputHeight} & = OH = \\frac{(H + 2P - FH)}{S} + 1 \\\\ \n",
    "\\text{OutputWeight} & = OW = \\frac{(W + 2P - FW)}{S} + 1\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Convolution layer 다음에 Pooling layer가 온다면 , Feature Map의 행과 열의 크기는 Pooling 크기의 배수여야합니다. Input size를 때문에 2의 배수로 넣는 경향이 있습니다.\n",
    "\n",
    "<br>\n",
    "\n",
    "__Pooling layer 의 사이즈를 결정__\n",
    "\n",
    "pooling layer 는 정사각형의 사이즈입니다. Pooling 사이즈를 Stride 사이즈와 같은 크기로 만든다면, 모든 요소가 Pooling 에 관여할 수 있습니다. \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{OutputRowSize} & = \\frac{InputRowSize}{PoolingSize} \\\\ \n",
    "\\text{OutputColumnSize} & = \\frac{InputColumnSize}{PoolingSize}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected Layer\n",
    "\n",
    "컨볼류션 계층에서 특징이 추출되었다면, 추출된 값을 기존의 뉴럴 넷에 넣어서 분류를 하게됩니다.\n",
    "<br>\n",
    "\n",
    "__SoftMax__\n",
    "<br>\n",
    "Activation 함수중 하나이지만, 일반적으로 Multiclass Classification에 사용되기도 합니다. y range 가 확률 도메인으로 결정되며, X 값에 따라서 모든 class의 확률값을 return 합니다.\n",
    "<br>\n",
    "\n",
    "__Dropout__\n",
    "<br>\n",
    "CNN 그래프에서 Softmax로 가기전에 Dropout 계층이 있습니다. 이는 over-fitting을 방지하기 위해 뉴럴 넷이 학습중일때, 랜덤하게 뉴런을 꺼서 학습을 방지하는 기법입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Implementation\n",
    "\n",
    "CNN의 구현은 다음과 같이 진행됩니다. \n",
    "\n",
    "- Convolution Layer\n",
    "    - Zero Padding\n",
    "    - Convolve window \n",
    "    - Convolution forward\n",
    "    - Convolution backward (optional)\n",
    "- Pooling Layer\n",
    "    - Pooling forward\n",
    "    - Create mask \n",
    "    - Distribute value\n",
    "    - Pooling backward (optional)   \n",
    "- Fully-Connected Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Zero Padding\n",
    "\n",
    "위에서 언급했듯이 Conv레이어를 지나게 되면서 shrinking 현상이 발생하게 됩니다. 따라서 Padding이 자연스럽게 필요하게 됩니다. Same conv를 구현하기 위해서 Padding이 필요하게 됩니다. np.pad를 활용하여 한번 구현해 봅시다.\n",
    "    \n",
    "__Argument__\n",
    "\n",
    "X : python numpy array of shape (m, n_H, n_W, n_C) \n",
    " - m : batch of m images\n",
    " - n_H : 데이터의 Hight\n",
    " - n_W : 데이터의 Width\n",
    " - n_C : 데이터의 Channel\n",
    " \n",
    "pad : padding numberd입니다.\n",
    "\n",
    "__Returns__\n",
    "\n",
    "X_pad : 패딩이 붙은 2D 이미지입니다. (m, n_H + 2*pad, n_W + 2*pad, n_C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3, 3, 2) (4, 7, 7, 2)\n"
     ]
    }
   ],
   "source": [
    "def zero_pad(X,pad):\n",
    "    X_pad = np.pad(X,((0,0),(pad,pad),(pad,pad),(0,0)),'constant',constant_values=0)\n",
    "    return X_pad\n",
    "\n",
    "x = np.random.randn(4,3,3,2)\n",
    "x_pad = zero_pad(x, 2)\n",
    "print(x.shape, x_pad.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Convolve Window\n",
    "\n",
    "이번에는 Filter를 이동시키며 convolution 연산하는 과정을 구해보려고 합니다. input의 volume을 받아서(3차원), 모든 position의 input에 filter를 적용해보고자합니다. Convolution 연산은 element wise multiplication으로 이루어집니다.\n",
    "    \n",
    "__Argument__\n",
    "\n",
    "- a_slice_prev : Filter가 적용될 Input입니다. (f, f, n_C_prev)\n",
    "- W : Filter의 사이즈입니다. (f, f, n_C_prev)\n",
    "- b : Bais입니다. - matrix of shape (1, 1, 1)\n",
    "    \n",
    "__Returns__\n",
    "\n",
    "- Z : Convolution 연산의 결과로 나오는 값입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_single_step(a_slice_prev, W, b):\n",
    "    # Element-wise product\n",
    "    s = a_slice_prev * W\n",
    "    # 채널을 기반으로 모두 더해줍니다.\n",
    "    Z = np.sum(s)\n",
    "    # Bias b를 더해줍니다.\n",
    "    Z = Z + np.float(b)\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z = -6.999089450680221\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "a_slice_prev = np.random.randn(4, 4, 3)\n",
    "W = np.random.randn(4, 4, 3)\n",
    "b = np.random.randn(1, 1, 1)\n",
    "Z = conv_single_step(a_slice_prev, W, b)\n",
    "print(\"Z =\", Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Convolutional Neural Networks - Forward pass\n",
    "\n",
    "Forward pass에서는 다양한 필터를 통해서, 구현을 위해 2D input의 horizental과 vertial index를 계산하면서 filter를 적용해보려고합니다. stack이 되는 output을 계산해 보려고합니다.\n",
    "\n",
    "<img src=\"img/vert_horiz.png\" width=50%>\n",
    "\n",
    "Convolution의 output shape을 결정하는 식은 다음과 같습니다.\n",
    "\n",
    "$$ n_H = \\lfloor \\frac{n_{H_{prev}} - f + 2 \\times pad}{stride} \\rfloor +1 \n",
    "$$\n",
    "\n",
    "$$n_W = \\lfloor \\frac{n_{W_{prev}} - f + 2 \\times pad}{stride} \\rfloor +1 $$\n",
    "\n",
    "$$n_C = \\text{number of filters used in the convolution}$$\n",
    "\n",
    "\n",
    "__Arguments__\n",
    "\n",
    "- A_prev : Input으로 들어가는 Matrix입니다. 데이터의 batch m, Hight, Width, Channel이 포함되어 있습니다. (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "- W : Weights, Filter입니다. (f, f, n_C_prev, n_C)\n",
    "- b : Biases (1, 1, 1, n_C)\n",
    "- hparameters : \"stride\" 와 \"pad\"를 결정하는 python dictionary입니다.\n",
    "\n",
    "__Returns__\n",
    "\n",
    "- Z : conv output입니다. (m, n_H, n_W, n_C)\n",
    "- cache : conv_backward() 에 도움을 줄 cache입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_forward(A_prev, W, b, hparameters):\n",
    "    # Input의 shpae을 정의합니다.\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    # filter의 shape을 정의합니다.\n",
    "    (f,f,n_C_prev,n_C) = W.shape\n",
    "    # input dictionary에서 받을 value 값입니다.\n",
    "    stride = hparameters['stride']\n",
    "    pad = hparameters['pad']\n",
    "    \n",
    "    # Conv의 output volumn을 정의해줍니다\n",
    "    n_H = int(((n_H_prev - f + (2*pad)) / stride)+1)\n",
    "    n_W = int(((n_W_prev - f + (2*pad)) / stride)+1)\n",
    "    \n",
    "    # output volumn을 initialize해줍시다\n",
    "    Z = np.zeros((m, n_H, n_W, n_C))\n",
    "    \n",
    "    # Padding을 설정해줍니다.\n",
    "    A_prev_pad = zero_pad(A_prev,pad)\n",
    "    \n",
    "    for i in range(m): #batch에 있는 traindata를 조회\n",
    "        a_prev_pad = A_prev_pad[i]\n",
    "        for h in range(n_H): #hight를 돌고\n",
    "            for w in range(n_W): #width를 돌고\n",
    "                for c in range(n_C): #Channel을 돌면서\n",
    "                    #input의 slice를 해줍시다\n",
    "                    vert_start = h*stride\n",
    "                    vert_end = vert_start+f\n",
    "                    horiz_start = w*stride\n",
    "                    horiz_end = horiz_start+f\n",
    "                    \n",
    "                    a_slice_prev = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end,:]\n",
    "                    Z[i,h,w,c]=conv_single_step(a_slice_prev,W[...,c],b[...,c])\n",
    "    assert(Z.shape == (m,n_H,n_W,n_C))\n",
    "    cache = (A_prev,W,b,hparameters)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(10,4,4,3)\n",
    "W = np.random.randn(2,2,3,8)\n",
    "b = np.random.randn(1,1,1,8)\n",
    "hparameters = {\"pad\" : 2,\n",
    "               \"stride\": 2}\n",
    "Z, cache_conv = conv_forward(A_prev, W, b, hparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z's mean = 0.048995203528855794\n"
     ]
    }
   ],
   "source": [
    "print(\"Z's mean =\", np.mean(Z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Forward Pooling\n",
    "\n",
    "Activation function은 잠시 넘어가고 이제 MAX-POOL과 AVG-POOL을 구현해 봅시다.\n",
    "\n",
    "패딩이 없다고 가정하고 Pooling을 구현해보려고합니다. 다음과 같은 공식을 기반으로 구현이 이루어집니다.\n",
    "\n",
    "$$ n_H = \\lfloor \\frac{n_{H_{prev}} - f}{stride} \\rfloor +1 $$\n",
    "$$ n_W = \\lfloor \\frac{n_{W_{prev}} - f}{stride} \\rfloor +1 $$\n",
    "$$ n_C = n_{C_{prev}}$$\n",
    "\n",
    "__Arguments__\n",
    "- A_prev : Input데이터입니다. 일반적으로 Convolution layer의 결과값이 됩니다. (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "- hparameters : \"f\" 와 \"stride\"가 담긴 dictionary입니다.\n",
    "- mode : \"max\" or \"average\"를 결정하는 인자입니다.\n",
    "\n",
    "__Returns__\n",
    "- A : pool layer의 output입니다. (m, n_H, n_W, n_C)\n",
    "- cache : Backward pass를 계산히기 위해 저장해두는 캐시입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_forward(A_prev, hparameters, mode=\"max\"):\n",
    "    # input의 shape을 받아옵니다\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    # filter size와 stride size를 받아옵니다.\n",
    "    f = hparameters[\"f\"]\n",
    "    stride = hparameters[\"stride\"]\n",
    "    # ouput dimension을 잡아줍시다\n",
    "    n_H = int(1+(n_H_prev-f)/stride)\n",
    "    n_W = int(1+(n_W_prev-f)/stride)\n",
    "    n_C = n_C_prev\n",
    "    \n",
    "    A = np.zeros((m, n_H, n_W, n_C))\n",
    "    \n",
    "    for i in range(m):\n",
    "        for h in range(n_H):\n",
    "            for w in range(n_W):\n",
    "                for c in range(n_C):\n",
    "                    vert_start = h*stride\n",
    "                    vert_end = vert_start + f\n",
    "                    horiz_start = w*stride\n",
    "                    horiz_end = horiz_start + f\n",
    "                    \n",
    "                    a_prev_slice = A_prev[i, vert_start:vert_end, horiz_start:horiz_end, c]\n",
    "                    \n",
    "                    if mode == \"max\":\n",
    "                        A[i,h,w,c] = np.max(a_prev_slice)\n",
    "                    elif mode == \"average\":\n",
    "                        A[i,h,w,c] = np.mean(a_prev_slice)\n",
    "                        \n",
    "    cache = (A_prev, hparameters)\n",
    "    assert(A.shape ==(m,n_H,n_W,n_C))\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1.74481176 0.86540763 1.13376944]]]\n",
      "\n",
      "\n",
      " [[[1.13162939 1.51981682 2.18557541]]]]\n",
      "[[[[ 0.02105773 -0.20328806 -0.40389855]]]\n",
      "\n",
      "\n",
      " [[[-0.22154621  0.51716526  0.48155844]]]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(2, 4, 4, 3)\n",
    "hparameters = {\"stride\" : 2, \"f\": 3}\n",
    "A, cache = pool_forward(A_prev, hparameters)\n",
    "print(A)\n",
    "A, cache = pool_forward(A_prev, hparameters, mode = \"average\")\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
