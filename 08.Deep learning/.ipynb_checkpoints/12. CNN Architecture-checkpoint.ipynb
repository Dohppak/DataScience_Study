{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Architectures\n",
    "\n",
    "이미지 분류에 있어서는 다양한 모형들이 ImageNet Challenge 를 통해서 나오게 되었습니다.\n",
    "\n",
    "### AlexNet (2012)\n",
    "\n",
    "Krizhevsky et al. 힌튼박사님의 박사과정 학생이였습니다.\n",
    "\n",
    "- 2개의 평행한 Convolution flow를 설계하게 됩니다. 2개의 GPU를 사용했기 때문이라고 합니다.\n",
    "- 224x224x3 의 input\n",
    "- 첫 conv는 11x11사이즈의 96개의 filter를 적용했습니다. \n",
    "- 두번째 conv는 5x5\n",
    "- 최초로 ReLU를 사용\n",
    "- Norm layers : Local Response Normalization (LRN)\n",
    "    - 활성화를 넘어서 2번째 레이어로 넘어간 부분에 대해서 Local적인 부분에 Normalization을 걸어주게 됩니다.\n",
    "    - 오늘날에는 batch normalization을 하게됩니다.\n",
    "- Heavy data augmentation\n",
    "- Dropout : 0.5\n",
    "- Batch Size : 128\n",
    "- SGD Momentum : 0.9\n",
    "- Learning rate with 1e-2 with anneling\n",
    "- L2 weight decay : 5e-4\n",
    "- 7CNN ensemble\n",
    "\n",
    "### VGGNet (2014)\n",
    "\n",
    "Simonyan and Zisserman\n",
    "\n",
    "- Small filter(3x3) and deeper network\n",
    "- Current standard deep CNN\n",
    "- Stack of two 3x3 filter\n",
    "    - Why? 3x3 filter를 두개 넣으면 5x5보다 파라미터가 작기 때문입니다.\n",
    "- NO LRN\n",
    "- ensembles\n",
    "- Total Memory : 24M * 4 bytes ~= 96MB / image\n",
    "- Total Paramas : 138M parameters\n",
    "\n",
    "### GoogLeNet (2014)\n",
    "\n",
    "Szegedy et al.\n",
    "\n",
    "- Deeper network with computional efficiency\n",
    "- No FC layer\n",
    "- Inception module\n",
    "    - Parallel filter multiple receptive field sizes\n",
    "    - Reduce parameters using 1x1 conv?\n",
    "        - 1x1 conv가 무엇일까요? 1x1 filter의 depth가 64개로 해서 depth를 줄이는 효과를 주게 됩니다.\n",
    "    - Only 5M parameters : x12 less than VGGNet\n",
    "    \n",
    "\n",
    "### ResNet (2015)\n",
    "\n",
    "- Very deep netwrok is hard to train!\n",
    "    - 레이어를 쌓을 수록, test error가 떨어지지 않습니다. \n",
    "- Residual connections 과 Highway를 넣어줍시다.\n",
    "    - Convolution 마다 Skip-connection을 뚫어주는 것이 아이디어 입니다.\n",
    "    - 이때 Same convlution을 통해서 같은 차원을 유지해야합니다\n",
    "    - 차원이 다를시에는 $a^{[l]}$에 linear transform을 해줄 wight를 곱해주어야합니다.\n",
    "    - relu에 의해 항등함수를 학습하기 매우 쉽습니다, 수행능력이 떨어지지 않는다는 것을 보장할 수 있습니다.\n",
    "- Loss function이 훨신 낮아보이게 됩니다.\n",
    "\n",
    "$$\n",
    "a^{[l+2]} = g(z^{[l+2]}+a^{[l]})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network in network\n",
    "\n",
    "1x1 convolution을 사용합니다. 일반적으로 Channel이 너무 클때, 이 채널의 지역적인 정보를 압축하고 싶을때 사용을 하게 됩니다. 또한 1x1를 쓰는것은 non-linearity를 주는 효과도 줄 수 있습니다. \n",
    "\n",
    "- 일반적으로 Channel이 1 이상인 경우 매우 중요한 역할을 합니다.\n",
    "- 채널간의 지역적인 특성을 반영할 수 있다는 장점을 가지게 됩니다. \n",
    "\n",
    "### Inception network\n",
    "\n",
    "1x1, 3x3, 5x5, pooling중에 어떤것이 좋은 컨볼루션일까요? Inception 모듈의 가장 큰 특징은 바로 이것입니다. 28x28x192짜리 input데이터를 다양한 Convolution과 pooling layer를 사용하여 28x28x256짜리 데이터로 변환시킵니다. \n",
    "\n",
    "하지만 이 계산은 높은 연산량을 시키게 됩니다. 만약 28x28x192를 5x5x32 Same Conv를 쓰게 된다면, 120M의 연산량이 발생하게 됩니다. 이러한 높은 연산량을 줄이기 위한 방법이 바로 위에서 소개한 1x1 Conv입니다.(bottleneck layer)\n",
    "\n",
    "- 28x28x192\n",
    "- Conv 1x1x192가 16개 존재하게 됩니다\n",
    "- 28x28x16\n",
    "- Conv 5x5x16이 32개를 배치합니다\n",
    "- 28x28x32\n",
    "\n",
    "120M에서 12.4M까지 연산량이 줄어들게 됩니다.\n",
    "\n",
    "- Side branch를 사용하여 중간중간 output 예측을 하게 만들어 줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
