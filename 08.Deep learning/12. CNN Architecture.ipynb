{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 분류에 있어서는 다양한 모형들이 ImageNet Challenge 를 통해서 나오게 되었습니다. 대부분의 모형들이 초기에는 많은 layer를 통해서 높은 성능을 추구하게 됩니다. 하지만 2가지 문제점이 CNN의 많은 layer를 막게 됩니다. 그 이유는 바로 Optimization과 Generalization의 문제입니다. CNN 아키텍쳐는 이 두가지 문제점을 풀기 위해서 나오기 시작합니다. 초기의 CNN 아키텍쳐의 경우에는 CNN Layer를 많이 쌓으면서 안정적으로 학습할 방법을 찾아보게 됩니다. 이 시대에서 중요했던 요인들은 바로 CNN의 Kernel사이즈를 변화시켜가면서 학습을 하기 시작합니다.\n",
    "\n",
    "## AlexNet (2012)\n",
    "\n",
    "Krizhevsky et al. 힌튼박사님의 박사과정 학생이였습니다. 2개의 평행한 Convolution flow를 설계하게 됩니다. 2개의 GPU를 사용했기 때문이라고 합니다.\n",
    "- 224x224x3 의 input\n",
    "- 첫 conv는 11x11사이즈의 96개의 filter를 적용했습니다. \n",
    "- 두번째 conv는 5x5\n",
    "- 최초로 ReLU를 사용\n",
    "- Norm layers : Local Response Normalization (LRN)\n",
    "    - 활성화를 넘어서 2번째 레이어로 넘어간 부분에 대해서 Local적인 부분에 Normalization을 걸어주게 됩니다.\n",
    "    - 오늘날에는 batch normalization을 하게됩니다.\n",
    "- 7CNN ensemble\n",
    "\n",
    "## VGGNet (2014)\n",
    "\n",
    "Simonyan and Zisserman은 3x3 Convolution을 Stack해서 안정적인 학습을 가져오게 했습니다. ((3x3)x3) Convolution은 (7x7) Convolution과 같은 Receptive field를 가지게 되면서 동시에 더 적은 파라미터와 함께 더 많은 non-linearity를 반영할수 있다는 장점이 있습니다.\n",
    "\n",
    "- Small filter(3x3) and deeper network\n",
    "- Stack of 3x3 filter\n",
    "    - 3x$(Cx((3x3)xC))$ = 27$C^{2}$\n",
    "    - $Cx((7x7)xC)$ = 49$C^{2}$\n",
    "- 더 많은 Non-linearity를 사용하게 됩니다.\n",
    "- Total Memory : 24M * 4 bytes ~= 96MB / image\n",
    "- Total Paramas : 138M parameters\n",
    "\n",
    "\n",
    "## Inception network (Google Net)\n",
    "\n",
    "1x1, 3x3, 5x5, pooling중에 어떤것이 좋은 컨볼루션일까요? Inception 모듈의 가장 큰 특징은 바로 이것입니다. 여러 Receptive fields를 가지는 Path들을 Concat해서 다양한 Sparse patterns을 찾게 됩니다. 28x28x192짜리 input데이터를 다양한 Convolution과 pooling layer를 사용하여 28x28x256짜리 데이터로 변환시킵니다. \n",
    "\n",
    "하지만 이 계산은 높은 연산량을 시키게 됩니다. 만약 28x28x192를 5x5x32 Same Conv를 쓰게 된다면, 120M의 연산량이 발생하게 됩니다. 이러한 높은 연산량을 줄이기 위한 방법이 바로 위에서 소개한 1x1 Conv입니다.(bottleneck layer)\n",
    "\n",
    "- 28x28x192\n",
    "- Conv 1x1x192가 16개 존재하게 됩니다\n",
    "- 28x28x16\n",
    "- Conv 5x5x16이 32개를 배치합니다\n",
    "- 28x28x32\n",
    "\n",
    "120M에서 12.4M까지 연산량이 줄어들게 됩니다.\n",
    "\n",
    "- Side branch를 사용하여 중간중간 output 예측을 하게 만들어 줍니다. \n",
    "\n",
    "\n",
    "### 1x1 Convolution\n",
    "\n",
    "1x1 convolution을 사용합니다. 일반적으로 Channel이 너무 클때, 이 채널의 지역적인 정보를 압축하고 싶을때 사용을 하게 됩니다. 또한 1x1를 쓰는것은 non-linearity를 주는 효과도 줄 수 있습니다. 이 1x1 Convolution은 Point-wise convolution이라고도 불립니다. 일반적으로 WxHxC의 영역에서 C을 mix할때 사용하게 됩니다. \n",
    "\n",
    "- 일반적으로 Channel이 1 이상인 경우 매우 중요한 역할을 합니다.\n",
    "- 채널간의 지역적인 특성을 반영할 수 있다는 장점을 가지게 됩니다. \n",
    "\n",
    "\n",
    "## ResNet (2015)\n",
    "Very deep netwrok is hard to train! 레이어를 쌓을 수록, test error가 떨어지지 않습니다. 대부분은 Overfitting이 발생하고 Optimization이 매우 어려워 진다는 문제점을 가지게 됩니다. 하지만 ResNet은 최초로 100개 이상의 CNN레이어를 안정적으로 학습시킨 모델입니다. 저자들은 non-linear layer가 identity function의 표현과 대립한다고 생각합니다. 이를 풀어서 생각해보면 NonLinear Layer에 의해서 input간의 interaction을 너무 많이 고려하다 보니 input 그 자체 대한 이해가 딸어지는게 아닐까라고 생각이 듭니다. 이에 대한 해결책은 생각보다 단순합니다. Identity input을 각 레이어에 대해서 Reparametrize해주는 것입니다. \n",
    "\n",
    "- Convolution Layer를 Time sequence라고 생각해볼까?\n",
    "    - RNN계열의 LSTM은 gradient vanishing을 Cell-state를 통해서 해결했습니다.\n",
    "    - Input을 마치 Cell-state와도 같이 단기적으로 기억할수 있는 Residual Connection을 만들어줍니다.\n",
    "- Residual connections 과 Highway를 넣어줍시다.\n",
    "    - Convolution 마다 Skip-connection을 뚫어주는 것이 아이디어 입니다.\n",
    "    - 이때 Same convlution을 통해서 같은 차원을 유지해야합니다\n",
    "    - 차원이 다를시에는 $a^{[l]}$에 linear transform을 해줄 wight를 곱해주어야합니다.\n",
    "    - relu에 의해 항등함수를 학습하기 매우 쉽습니다, 수행능력이 떨어지지 않는다는 것을 보장할 수 있습니다.\n",
    "- Loss function이 훨신 낮아보이게 됩니다.\n",
    "- 더 많은 Residual Channel을 만들었더니 더 잘됩니다. \n",
    "$$\n",
    "a^{[l+2]} = g(z^{[l+2]}+a^{[l]})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficient Models\n",
    "\n",
    "CNN모델의 다른 트렌드는 바로 효율적인 모델입니다. 위에 ResNet은 bottleneck을 활용하여 연산의 효율성과 동시에 많은 레이어의 학습을 가능하게 했습니다. 이와 같이 연산의 효율성은 한정된 computing budget(10-140 MFLOPs)을 가지는 Mobile 환경에서 중요하게 됩니다. 일반적으로 Depthwise separable convolution 또는 Group Convolution의 경우에는 CNN블록이 Representation capability와 computational cost사이의 trade-off 관계를 가지게 됩니다. \n",
    "\n",
    "ResNeXt의 경우에는 93.4%의 계산량(Multiplication-add)가 1x1 convolution에 의해서 결정되게 됩니다.(Cardinality =32) 이와 같은 문제의 가장 쉬운 해결책은 바로 Grouped Convolution입니다. 특정 채널간의 독립성을 가정하고, 채널의 연산을 그룹을 지어서 연산하게 됩니다. 하지만 이러한 Grouped Convolution의 단점은 특정 채널로부터 연산된 output이 input channel중 아주 작은 요소에 의해서 영향을 받게 된다는 점입니다.\n",
    "\n",
    "## ResNeXt\n",
    "ResNeXt의 경우에는 93.4%의 계산량(Multiplication-add)가 1x1 convolution에 의해서 결정되게 됩니다.(Cardinality =32)\n",
    "\n",
    "\n",
    "## MobileNet\n",
    "\n",
    "### Group Convolution & Depthwise Convolution \n",
    "\n",
    "## ShuffleNet\n",
    "실질적인 하드웨어를 기반으로 실험을 해서 알렉스넷 대비해서 13배의 Speed 향상을 이루어 냈습니다. ResNeXt에서 \n",
    "\n",
    "### Channel Shuffle\n",
    "\n",
    "## MobileNet-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
