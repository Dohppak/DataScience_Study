{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
    "- https://pytorch.org/docs/stable/nn.html#loss-functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Loss function\n",
    "\n",
    "우리의 목적은 데이터를 잘 설명할 분포를 따르는 것입니다. Loss function은 연속적이고 미분가능한게 좋습니다.\n",
    "\n",
    "$$\n",
    "E_{D}[l(\\hat{y},y)] = \\int_{x,y}l(\\hat{y},y)*P_{D}(x,y)dxdy \\\\\n",
    "E_{D}[l(\\hat{y},y)] \\approx \\frac{1}{N}\\sum_{i}^{N}l(\\hat{y},y)\n",
    "$$\n",
    "- input data x, target y, y는 분포 D를 따른다고 가정합니다.\n",
    "- Classfier model의 output은 $\\hat{y}$이며, x를 모델에 넣어서 나온 output입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the Classification metrics section of the user guide for further details.\n",
    "\n",
    "- accuracy_score(y_true, y_pred[, …])\tAccuracy classification score.\n",
    "- auc(x, y[, reorder])\tCompute Area Under the Curve (AUC) using the trapezoidal rule\n",
    "- brier_score_loss(y_true, y_prob[, …])\tCompute the Brier score.\n",
    "- cohen_kappa_score(y1, y2[, labels, …])\tCohen’s kappa: a statistic that measures inter-annotator agreement.\n",
    "- f1_score(y_true, y_pred[, labels, …])\tCompute the F1 score, also known as balanced F-score or F-measure\n",
    "- hamming_loss(y_true, y_pred[, …])\tCompute the average Hamming loss.\n",
    "- hinge_loss\n",
    "    - max(0,$1-y(wx+b)$)\n",
    "    - 1보다 작을때는 Lienar한 함수가, 1보다 클때는 0이 된다.\n",
    "- jaccard_similarity_score(y_true, y_pred)\tJaccard similarity coefficient score\n",
    "- log_loss (logistic loss or cross-entropy loss)\n",
    "    - 0일때 1이며, 연속적이고, 부드러운 감소함수가 된다. \n",
    "- matthews_corrcoef(y_true, y_pred[, …])\tCompute the Matthews correlation coefficient (MCC)\n",
    "- precision_score(y_true, y_pred[, …])\tCompute the precision\n",
    "- recall_score(y_true, y_pred[, …])\tCompute the recall\n",
    "- roc_auc_score(y_true, y_score[, …])\tCompute Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores.\n",
    "- zero_one_loss\n",
    "    - $y = \\hat{y}$ 인 경우는 0\n",
    "    - $y$ != $\\hat{y}$ 인 경우는 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pytoch Loss functions\n",
    "- L1Loss\n",
    "- MSELoss\n",
    "- CrossEntropyLoss\n",
    "- CTCLoss\n",
    "- NLLLoss\n",
    "- PoissonNLLLoss\n",
    "- KLDivLoss\n",
    "- BCELoss\n",
    "- BCEWithLogitsLoss\n",
    "- MarginRankingLoss\n",
    "- HingeEmbeddingLoss\n",
    "- MultiLabelMarginLoss\n",
    "- SmoothL1Loss\n",
    "- SoftMarginLoss\n",
    "- MultiLabelSoftMarginLoss\n",
    "- CosineEmbeddingLoss\n",
    "- MultiMarginLoss\n",
    "- TripletMarginLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0-1loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Surrogate loss function \n",
    "\n",
    "연속적이며, 미분가능한 함수가 필요합니다. 또한 정규화가 가능하면 더 좋습니다\n",
    "$$\n",
    "min_{\\theta}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hinge loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
