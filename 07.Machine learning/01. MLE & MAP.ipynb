{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference\n",
    "\n",
    "- https://taeoh-kim.github.io/blog/bayesian-deep-learning-introduction/\n",
    "- http://sanghyukchun.github.io/58/\n",
    "- http://sanghyukchun.github.io/61/\n",
    "- https://ratsgo.github.io/generative%20model/2017/12/17/compare/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "- 주어진 데이터를 잘 설명하는 '함수' 를 찾는 알고리즘\n",
    "- '함수?' : 확률 분포\n",
    "    - 어떤 확률 분포를 가정하고, 적절한 확률 분포의 parameter를 유추하는 과정이다.\n",
    "    - 데이터로 부터 parameter를 estimation해보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning\n",
    "\n",
    "Input과 Target을 가진 Pair-dataset을 가지고 Output이 Target에 가깝도록 만드는 학습입니다.\n",
    "\n",
    "- Regression\n",
    "    - output 이 continuous value로 나옵니다\n",
    "    - predict a response for the new input\n",
    "\n",
    "- Classification\n",
    "    - output이 discrete categorical labels로 나옵니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Learning\n",
    "\n",
    "Input을 가진 Pair-dataset을 가지고 latent value를 찾아냅니다.\n",
    "\n",
    "- Clustering\n",
    "    - Latent 한 Group에 대한 value를 찾아냅니다\n",
    "\n",
    "- Density estimation\n",
    "    - 주어진 데이터셋을 확률 분포에 Fitting시킵니다. \n",
    "    - 가정한 모델을 데이터셋에 피팅시킵니다. -> 데이터가 모델을 잘 설명해줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Theory\n",
    "\n",
    "내가 과연 추론한 파라미터는 적절한가? 어떻게 decision을 할 수 있는가? \n",
    "\n",
    "- Inference\n",
    "    - training data를 사용하여 model을 learning한다.\n",
    "- Decision\n",
    "    - 위에서 계산한 posterior probability를 사용하여 실제 class assignment decision을 내리게 된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision을 내리는 2가지 방법\n",
    "\n",
    "- Generative model\n",
    "    - $y$ 즉 class의 분포에 주목한다.\n",
    "    - Classifier 는 각각 클래스의 확률분포에 기반한다. $P(x|y)$\n",
    "        - GMM, Naive Bayes\n",
    "        \n",
    "        \n",
    "- Discriminative Model\n",
    "    - $y$ class의 차이에 주목한다.\n",
    "    - Classifier 는 확률값에 기반한다 $P(y|x)$\n",
    "        - Logistic regression, SVM, Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Rules in Machine Learning\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "arg\\max _{ y }{ p(y|x) } =&arg\\max _{ y }{ \\frac { p(x|y)p\\left( y \\right)  }{ p\\left( x \\right)  }  }\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "위 수식을 해석해 보면 Input $X$ 가 주어질때, $Y$가 나올 확률이 좌변에 존재하게 되고, 확률을 활용하에 task를 해결한다.\n",
    "\n",
    "- $p(y|x)$ : Posterior\n",
    "- $p(x|y)$ : Likelihood\n",
    "- $p(y)$ : Prior\n",
    "- $p(x)$ : Evidence\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian\n",
    "\n",
    "베이지안은 우리가 궁금한 것을 Prior로 놓는 것이다. 그렇다면 일반적으로 우리가 궁금한 것은 $W$이다. 따라서 수식을 조금 수정해보자\n",
    "$$\n",
    "\\begin{align*}\n",
    "arg\\max _{w}{ p(w|x,y) } =&arg\\max _{w}{ \\frac { p(y|w,x)p\\left( w \\right)  }{ p\\left( y|x \\right)  }  }\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "- $p(w|x,y)$ : Posterior\n",
    "    - Input, Output이 주어졌을 경우의 Weight의 확률\n",
    "- $p(y|w,x)$ : Likelihood\n",
    "    - Input과 weight가 주어졌을대의 ouput의 확률\n",
    "- $p(w)$ : Prior\n",
    "    - 우리가 궁금한 w\n",
    "- $p(y|x)$ : Evidence\n",
    "    - Input이 주어졌을때의 ouput의 확률\n",
    "    - Marginal Likelihood로 W에 대해서 marginalization을 한 결과라고 생각하면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data View\n",
    "\n",
    "$x,y$는 데이터셋에서 나오니 이 둘을 Data라고 생각하고 묶는다면 다음과 같이 쓸수 있다.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "arg\\max _{w}{ p(w|D) } =&arg\\max _{w}{ \\frac { p(D|w)p\\left( w \\right)  }{ p\\left(D\\right)  }  }\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE (Maximum likelihood Estimation)\n",
    "\n",
    "> 주어진 Traning Data를 가장 잘 설명하는 $w$를 찾아라!, Parameter is distribution of y?\n",
    "\n",
    "### Binominal\n",
    "- Independent events\n",
    "- Identically distributed according to distribution\n",
    "- Binominal Distribution\n",
    "을 가정해보자.\n",
    "\n",
    "$$\n",
    "P(D|\\theta) = \\theta^{\\alpha_{T}}(1-\\theta)^{\\alpha_{F}}\n",
    "$$\n",
    "- $D$는 관측한 정보입니다.\n",
    "- $\\theta$는 Binominal 분포에서 참이 나오는 확률입니다.\n",
    "\n",
    "#### Hypothesis\n",
    "우리의 event의 result는 가정한 distribution 의 $\\theta$를 따른다.\n",
    "- 그렇다면 $\\theta$를 어떻게 잡아야하는가?\n",
    "- 가정을 강하게 만들기 위한 방법론이 바로 MLE이다!\n",
    "- 데이터를 가장 잘 설명할수 있는 $\\theta$를 찾아보자!\n",
    "\n",
    "$$\n",
    "\\hat{\\theta}=argmax_{\\theta}P(D|\\theta)\\\\\n",
    "\\hat{\\theta}=argmax_{\\theta}\\log{P(D|\\theta)}\n",
    "$$\n",
    "로그는 단조증가함수 이기 때문에 영향을 끼치지 않는다\n",
    "- $\\theta$ 에 대해서 미분을해서 모르는 변수를 최적화 시킨다.\n",
    "\n",
    "#### Simple Error Bound\n",
    "$$\n",
    "p(|\\hat{\\theta}-\\theta^{*}|\\geq \\epsilon) < 2e^{-2N\\epsilon^{2}}\n",
    "$$\n",
    "\n",
    "N이 증가할수록 에러가 줄어들 것입니다.\n",
    "- 오차 범위 안에서는 $\\theta$가 믿을만 합니다\n",
    "- Probably Approximate Correct Learning (PAC Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAP(Maximize Posterior)\n",
    "\n",
    "- Prior 를 넣을수 있습니다.\n",
    "- 사전정보가 추가된 $\\theta$를 사용해봅시다\n",
    "$$\n",
    "P(\\theta|D) = \\frac{P(D|\\theta)P(\\theta)}{P(D)}\n",
    "$$\n",
    "\n",
    "데이터가 주어졌을때의 $\\theta$ 의 확률을 구할수 있습니다.\n",
    "\n",
    "$$\n",
    "\\hat{\\theta}=argmax_{\\theta}P(\\theta|D)\\\\\n",
    "$$\n",
    "\n",
    "beta distribution을 이용해서 사전정보를 넣을 수 있게된다. Prior정보를 주게 됩니다. 따라서 정보가 적을때는 매우 사용하기 좋습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
