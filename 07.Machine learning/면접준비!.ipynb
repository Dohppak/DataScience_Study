{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 고유값(eigen value)와 고유벡터(eigen vector)에 대해 설명해주세요. 그리고 왜 중요할까요?\n",
    "\n",
    "선형변환에 대한 주축을 찾는 문제이다. 어떠한 선형변환 A를 했을 때, 그 크기만 변하고 방향이 변하지 않는 백터가 있는가?, 그 백터는 얼마나 변했는가?\n",
    "\n",
    "It is a problem of finding the main axis for linear transformation. When doing any linear transformation, is there a vector that only changes its size and does not change its direction?, how much has that vector changed?\n",
    "\n",
    "### 확률 모형과 확률 변수는 무엇일까요? What is a probability model and a random variable?\n",
    "확률 모형은 특정한 분포 특성을 가지는 데이터를 만들어 내는 일종의 활동, 확률 변수는 표본공간 상에서 하나의 사건에 하나의 실수값을 대응시키는 함수\n",
    "\n",
    "Probability model is a kind of activity that creates data with specific distribution characteristics, and random variable is a function that maps one real value to one event in the sample space.\n",
    "\n",
    "### 조건부 확률은 무엇일까요?\n",
    "B가 사실인 경우에 한해 사건 A에 대한 확률을 구하는 것이다.\n",
    "\n",
    "Only if B is true, we find the probability for event A.\n",
    "\n",
    "### 공분산과 상관계수는 무엇일까요?\n",
    "공분산의 경우는 자료가 평균값으로부터 얼마나 떨어져 있는가?에 관한 크기(분산에도 나와있음)과 방향성, 상관계수는 방향성 만을 분리해서 보는것, 공분산을 샘플 표준편차로 정규화하여 정의합니다.\n",
    "\n",
    "In the case of covariance, the magnitude (shown in variance), direction, and correlation coefficient regarding how far the data are from the mean value are defined by separating only the direction and normalizing the covariance to the sample standard deviation.\n",
    "\n",
    "### p-value란?\n",
    "p-value는 이 검정 통계량에 관한 확률인데, 우리가 얻은 검정 통계량보다 크거나 같은 값을 얻을 수 있을 확률을 의미한다. \"우리가 얻은 데이터에 있는 두 표본 집단이 같은 모집단에서부터 나온거라고 치자. 그랬을 때, 우리가 이런 검정 통계량(가령, t-value)을 얻었는데 이게 얼마나 말이되는거냐?\"\n",
    "\n",
    "The p-value is the probability for this test statistic, which means the probability of getting a value that is greater than or equal to the test statistic we obtained. \"Let's say that the two sample groups in the data we get come from the same population. When we do, we get these test statistics (eg t-value). How much does that make sense?\"\n",
    "\n",
    "### 중심극한정리는 왜 유용한걸까요?\n",
    "표본 평균의 분포는 정규 분포에 근사하게 된다. 심지어는 표본을 추출하는 모집단이 서로 독립적이라면 여러 모집단에서 추출한 표본이더라도 표본 평균의 분포는 정규분포에 근사하게 된다.\n",
    "\n",
    "The distribution of the sample means approximates the normal distribution\n",
    "\n",
    "### 엔트로피(entropy)에 대해 설명해주세요. 가능하면 Information Gain도요.\n",
    "필자는 통계학에서 말하는 정보량을 `깜놀도`라고 말하고 싶다. 이 개념은 확률의 개념을 재해석 한 것으로도 볼 수 있는데, 다시 말해 확률이 낮은 사건일 수록 정보량은 높다. 거의 일어나지 않을 일이기 때문이다.\n",
    "\n",
    "정보량을 정의할 때 왜 굳이 log를 붙여서 정의했을까? 확률값(혹은 확률밀도 값)에 반비례 해야 하기 때문. 두 사건의 정보량을 합치면 각 사건의 정보량을 합친 것과 같아야 함.\n",
    "\n",
    "$$\n",
    "I(x) = -\\log_b(P(X))\n",
    "$$\n",
    "\n",
    "\n",
    "### KL divergence\n",
    "KL divergence를 생각할 때는 “divergence”라는 말에만 주목하면 된다는 것인데, 이 divergence의 의미는 벡터장의 발산 같은 개념이 아니라, 그저 “차이”를 다른 말로 쓴 것일 뿐이다는 것을 명심해야 한다. 이 때 정보 엔트로피를 이용해 비교가 진행되다 보니 KL divergence를 또 다른 말로 relative entropy라고 부르기도 한다. Compare distribution\n",
    "\n",
    "$$\n",
    "BCE = \\sum_{x\\in{0, 1}}\\left(-P(x)\\log(Q(x))\\right)\n",
    "$$\n",
    "\n",
    "### MLE란?\n",
    "Sample들을 보고, 어떤 평균값을 가지는 확률 밀도에서 샘플들이 추출되었는지를 찾는 방법이다. 표본을 보고 분포의 파라미터를 추정하는 방법이다. \n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\theta}L(\\theta|x) = \\frac{\\partial}{\\partial \\theta}\\log P(x|\\theta) = \\sum_{i=1}^{n}\\frac{\\partial}{\\partial\\theta}\\log P(x_i|\\theta) = 0\n",
    "$$\n",
    "\n",
    "### MLE의 단점은 무엇이고, 이를 MAP는 어떻게 보안했나요??\n",
    "MLE의 단점은 관측된 결과에 의해 확률이 결정되기 때문에, 예외적인 결과(극단적인 값)가 반영될 경우 결과 값이 왜곡될수 있습니다. MAP의 보안된 속성, 사전확률 정보를 알고 있다면, 베이즈 정리를 통해, 사후확률을 추론할 수 있기 때문에, 현실적인 추론이 가능해집니다. 대부분의 경우 우리는 데이터를 통해 사전 정보를 알고 있는 경우가 많으며, 이를 통해 사후 확률을 추론하는 경우가 많아 현실 문제에 적합합니다.\n",
    "\n",
    "### 그렇다면 MAP의 단점은?\n",
    "데이터의 부족 : 데이터가 부족시 사전확률에 대핸 정보가 부족할 수 있습니다. 사전 정보의 사전지식 부족 : a, b에 대한 가정이 만약 부족하거나 잘못되었다면 문제가 생긴다.\n",
    "\n",
    "### Likelihood Function\n",
    "likelihood는 얻은 데이터가 특정 분포에서 나왔을 가능도를 말한다. 때문에 이 가능도를 계산하기 위해서는 각 데이터 샘플에서 후보 분포에 대한 기여도를 계산해서 곱해야한다. 모든 데이터는 독립적으로 연달아 일어나기 때문이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Gradient Descent\n",
    "MLE를 위해서는 주로 우리는 함수의 최소값을 찾아야 하는데, 우리가 주로 실제 분석에서 맞딱드리게 되는 함수들은 닫힌 형태(closed form)가 아니거나 함수의 형태가 복잡해 (가령, 비선형함수) 미분계수와 그 근을 계산하기 어려운 경우가 많고, 데이터 양이 매우 큰 경우 gradient descent와 같은 iterative한 방법을 통해 해를 구하면 계산량 측면에서 더 효율적으로 해를 구할 수 있다.\n",
    "\n",
    "### Gradient with Momentum\n",
    "Exponentially Weighted Moving Average,\n",
    "\n",
    "RMSProp이 가지는 의의는 각 parameter 별로 적절히 learning rate의 크기를 조절해줄 수 있다는데 있다. Gradient의 방향을 이용하지 않고 그 크기만을 이용해 업데이트 해주고자 하는 각 parameter에 대한 학습 속도를 조절한다.\n",
    "\n",
    "### ROC Curve\n",
    "\n",
    "\n",
    "### 정규화를 왜 해야할까요? 정규화의 방법은 무엇이 있나요?\n",
    "\n",
    "### Local Minima와 Global Minima에 대해 설명해주세요.\n",
    "\n",
    "### ROC 커브에 대해 설명해주실 수 있으신가요?\n",
    "\n",
    "### L1, L2 정규화에 대해 설명해주세요\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
