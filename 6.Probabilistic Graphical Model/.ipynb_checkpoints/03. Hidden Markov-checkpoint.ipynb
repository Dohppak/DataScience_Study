{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Markov model\n",
    "\n",
    "공간과 달리 __비가역적인 요소인 시간__ 이라는 요소를 모델링 하기 위해 접근해 보자\n",
    "\n",
    "- Transition from the static clustering to the dynamic clustering\n",
    "- Understand the difference of the graphical model\n",
    "- Modeling\n",
    "    - Evaluation\n",
    "        - Given : $\\pi, a, b$\n",
    "        - Find : $P(X|M,\\pi, a, b)$\n",
    "        - Markov 모델로부터 $X$ 가 generate 되었을때 얼마나 likely 한지 판단하게 된다\n",
    "    - decoding\n",
    "        - Given : $\\pi, a, b$\n",
    "        - Find : $argmax_{z}P(Z|X, M,\\pi, a, b)$\n",
    "        - Markov 모델로부터 가장 likely한 $Z$, latent factor 의 시퀀스가 무었인지 제시하여라\n",
    "    - learning \n",
    "        - Given : $X$\n",
    "        - Find : $argmax_{\\pi, a, b}P(X|M,\\pi, a, b)$\n",
    "        - X가 알려져 있을때, 주어진 데이터를 보일 확률을 maximize 해주는 paramter를 찾아보아라."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal relation\n",
    "\n",
    "Causality from time $t$ to time $t+1$\n",
    "\n",
    "- Observation $x_{1},x_{2}...x_{T}$\n",
    "discrete 하거나 continuous한 data 모두 가능하다.\n",
    "    - 데이터의 Probability distribution이 무엇인지가 중요하다\n",
    "    \n",
    "- Latent state $z$\n",
    "$K$개의 Vector variable이다. 역시 discrete & Continuous 할 수 있다.\n",
    "    - 만약 latent factor 가 continuous 하다면 그것을 칼만 필터라고 부른다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](images/HMM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Initial State probability ($\\pi$)\n",
    "\n",
    "Multinomial distirbution을 따르는 $P(z_{1})$ ~ $Mult(\\pi_{1},...\\pi_{k})$\n",
    "- Parameter = $\\pi$\n",
    "\n",
    "##### Transition Probability ($a_{i,j}$)\n",
    "$P(z_{t}|z^{i}_{t-1}=1)$ ~ $Mult(a_{i,k})$\n",
    "- Paramter = $a_{i,k} = P(z^{j}_{t}=1 |z^{i}_{t-1}=1)$\n",
    "- $a_{i,j}$ : $t-1$에서는 $i$번째 클러스터 이였다가 $t$에서는 $j$번째로 바뀌게 될 확률\n",
    "    \n",
    "##### Emission Probability ($b_{i,j}$)\n",
    "특정 클러스터로 assigment 되어있을때, 어떤 데이터 포인트가 관측될 것인가?\n",
    "<br>\n",
    "$P(x_{t}|z^{i}_{t}=1)$~$Mult(b_{i,m})$~$f(x_{t}|\\theta_{i})$\n",
    "- $b_{i,j} = P(x^{j}_{t}|z^{i}_{t}=1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marginal Probability in HMM\n",
    "\n",
    "일반적으로 우리는 Z라는 latent factor를 모르기 때문에, 알고싶은 X를 위해서 Z를 marginalize하게 됩니다.\n",
    "\n",
    "- $P(X|\\pi, a, b) = \\Sigma_{z}P(X,Z | \\pi, a,b)$\n",
    "\n",
    "즉 우리가 알고싶은 어떠한 random variable의 확률값이란\n",
    "\n",
    "- $P(X)$ = $\\sum_{z}P(X,Z)$ = $\\sum_{z_{1}}...\\sum_{z_{t}}P(x_{1},...x_{t},z_{1},...z_{t})$\n",
    "- = $\\sum_{z_{1}}...\\sum_{z_{t}}$ $\\pi_{z_1}$ $\\prod_{t=2}^{T}$ = $a_{z_{t-1},z_{t}}$ $\\prod_{t=1}^{T}$ $b_{z_{t},x_{t}}$\n",
    "\n",
    "위 구조는 여러번 반복해서 계산해야하는 비효율적인 구조입니다.\n",
    "- $P(A,B,C) = P(A)P(B|A)P(C|A,B)$\n",
    "\n",
    "이러한 형태로 recursive 하게 표현을 해봅시다. 위 topology 구조를 활용해서 network의 independent 한 친구들을 연산에서 지워낸다면, t라는 시점에서 k번째 클러스터에 할당된 random variable x들의 확률값은 다음과 같이 정의 할 수 있습니다.\n",
    "\n",
    "- $P(x_{1},...x_{t},z_{t}^{k}=1)$=$b_{z_{t}^{k},x^{t}}\\sum_{z_{t-1}} P(x_1,...x_{t-1},z_{t-1})a_{z_{t-1},z_{t}^{k}}$\n",
    "\n",
    "- $P(x_{1},...x_{t},z_{t}^{k}=1) = \\alpha_{t}^{k}$\n",
    "\n",
    "- $\\alpha_{t}^{k}$\n",
    "\n",
    "t라는 타임에 k라는 latent factor를 가지를 Random variable$X$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Probability Calculation\n",
    "\n",
    "Forward Probability = $\\alpha^{k}_{t}$\n",
    "- Dimension : Time x State\n",
    "- Latent factor $z$를 모른다고 할때, 주어진 $x$ 에 대해서 evaluation을 해보자\n",
    "    - $\\alpha^{k}_{t}$, $X$를 안다고 할때, 우리가 $P(X)$를 알수 있다.\n",
    "    \n",
    "##### Forward Algorithm\n",
    "\n",
    "x라는 random variable이 시간 t에 따라 state가 변화하며 그것을 우리는 $x_1,x_2,...,x_t$ 로 표현한다. 하지만 이때 x는 latent factor z에 속하게 되는데, 모든 z에 대해서 Forward를 알게 된다면 우리는 evaluation을 할 수 있다.\n",
    "- Initalize\n",
    "    - $\\alpha^{1}_{t}$ = $b_{k,x_{1}}\\pi_{k}$\n",
    "        - $b_{i,j} = P(x^{j}_{t}|z^{i}_{t}=1)$ 특정 클러스터로 assigment 되어있을때, 어떤 데이터 포인트가 관측될 것인가?\n",
    "        - Multinomial distirbution을 따르는 $P(z_{1})$ ~ $Mult(\\pi_{1},...\\pi_{k})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
