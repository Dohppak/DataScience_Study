{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "본 컨텐츠는 Christopher D. Manning, Prabhakar Raghavan and Hinrich Schütze, Introduction to Information Retrieval [Introduction to Information Retrieval](https://nlp.stanford.edu/IR-book/)Cambridge University Press. 2008을 번역한 글입니다. \n",
    "\n",
    "### Definition\n",
    "우선 먼저 알아보고자 하는것은 Information Retrieval(IR)의 정의입니다. 정보검색(IR)은 거대한 데이터 집합에서 사용자의 정보니즈를 충족하는 비 정형화된 데이터를 찾아주는 것입니다.\n",
    "\n",
    "`\n",
    "Information retrieval (IR) is finding material (usually documents) of an unstructured nature (usually text) that satisfies an information need from within large collections (usually stored on computers)\n",
    "`\n",
    "\n",
    "현재 세계의 변화로 인해서 많은 사람들이 Web search engine을 통해서 정보검색을 하고 있습니다. 하지만 정보 과다로 인하여 동일한 query에 대해서 return할 수 있는 정보가 너무 많아지게 되고, 우리는 사용자의 information need에 맞는 정보를 찾아줘야할 필요성이 생기게 되었습니다. 이러한 IR은 크게 3가지 분야에서 각광 받게 됩니다.\n",
    "- Web Search\n",
    "- Personal Information retrieval\n",
    "- Domain specific search\n",
    "\n",
    "### Database vs IR System\n",
    "\n",
    "IR 방식의 검색은 전통적인 데이터베이스 방식의 검색과 다르게 \"Specific\"한 데이터 뿐만 아니라 \"Similiar\"한 데이터 또한 검색 가능하게 합니다. IR system은 Browsing이나 Filtering, Clustering 그리고 새로운 Retrieved Material을 추가하는 처리도 지원하게 됩니다. \n",
    "\n",
    "\n",
    "### Information Retrieval Task\n",
    "정보 검색 시스템은 데이터집합, 색인, 랭킹, 표현, 사용자 피드백이라는 요소가 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def find_dcg(element_list):\n",
    "    \"\"\"\n",
    "    Discounted Cumulative Gain(DCG)\n",
    "    \"\"\"\n",
    "    scroe = 0.0\n",
    "    for order, rank in enumerate(element_list):\n",
    "        scroe += float(rank)/math.log((order+2))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ndcg(reference, hypothesis):\n",
    "    \"\"\"\n",
    "    Normalized Discounted Cumulative Gain(nDCG):\n",
    "        nDCG = DCG(hypotheiss)/DCG(reference)\n",
    "    \"\"\"\n",
    "    return find_dcg(hypothesis)/find_dcg(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_precision_k(reference, hypothesis, k):\n",
    "    \"\"\"\n",
    "    Precision at K\n",
    "    The measure is similar to precision but takes into account first k elements\n",
    "    \"\"\"\n",
    "    precision = 0.0\n",
    "    relevant = 0.0\n",
    "    \n",
    "    for i, value in enumerate(hypothesis[:k]):\n",
    "        if value == reference[i]:\n",
    "            relevant += 1.0\n",
    "        precision = relevant/k\n",
    "        \n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_precision(reference, hypothesis):\n",
    "    return find_precision_k(reference, hypothesis, len(reference))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_avaerage_precision(reference, hypothesis):\n",
    "    s_total = sum([find_precision_k(reference, hypothesis, k+1) for k in range(len(reference))])\n",
    "    return s_total / len(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
